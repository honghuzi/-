# 其它问题
## 过拟合
拟合一个统计模型时，使用过多参数。太适应数据而非一般情况。
回归问题中解决的方法有：减少特殊维度、正则化

## 解决技巧
交叉验证、提早停止、贝斯信息量准则、赤池信息量准则或模型比较。

## 梯度下降法
### 局限
一般而言，只能找到一个局部最优解，如果损失函数是凸函数，则一定可以得到全局最优解。

### 相关概念
1. 步长
2. 特征。样本输入部分
3. 假设函数
4. 损失函数。损失函数极小化，则拟合程度最好，对应为最优参数。一般用样本输出和假设函数的差取平方求和得到。

## 监督学习
### 分类和回归
1. 预测变量是离散 - 分类
2. 预测变量是连续 - 回归

## 梯度下降和最小二乘
### 相同点
1. 都是给出估值函数，求参数
2. 都是要残差平方和最小

### 不同点
1. 最小二乘是直接求导，找出全局最小，非迭代。
2. 梯度下降是给出一个任意参数向量，求出局部最小，是迭代法。

## 支持向量机 （SVM）
### 核函数
1. 把空间映射到更高的维度来进行非线性数据的分类。
2. 计算成本很大
   
### 支持向量
离分界线最近的点（向量），正是这些向量支持（定义）了机（分类器）

### 松弛变量
不要求完美地把所有的样本按需求分类开，用一个松弛变量定义这个不完美的程度。